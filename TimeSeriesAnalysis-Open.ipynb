{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from cv2 import VideoWriter, VideoWriter_fourcc\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy import signal, ndimage, spatial\n",
    "from scipy.signal import correlate\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import math \n",
    "from signal_alignment import phase_align, chisqr_align\n",
    "from scipy.interpolate import interp1d\n",
    "import scipy.stats as stats\n",
    "from scipy import fftpack\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_wave_df(DF):\n",
    "    # dropping columns with no value\n",
    "    #DF = DF.dropna(axis =1) \n",
    "    # dropping wave id column\n",
    "    DF = DF.drop(columns = 2, axis =1)\n",
    "    # name the first sensor columns \n",
    "    cols_0={0: \"Time\", 1: \"FrameID\", 3: \"SensorID\", 4: \"Sensor_1Status\", 5: \"X_Nose\", 6: \"Y_Nose\", 7:\"Z_Nose\"}\n",
    "    DF = DF.rename(columns=cols_0, errors=\"raise\")\n",
    "    DF = DF.drop(columns = [8,9,10, 11], axis =1)\n",
    "    \n",
    "    DF = DF.drop(columns = [12,13,14,15,16,17,18,19,20], axis =1)\n",
    "    cols_1={21: \"SensorID\", 22: \"Sensor_2Status\", 23: \"X_LLeft\", 24: \"Y_LLeft\", 25:\"Z_LLeft\"}\n",
    "    DF = DF.rename(columns=cols_1, errors=\"raise\")\n",
    "    \n",
    "    DF = DF.drop(columns = [26,27,28,29], axis =1)\n",
    "    cols_2={30: \"SensorID\", 31: \"Sensor_3Status\", 32: \"X_LR\", 33: \"Y_LR\", 34:\"Z_LR\"}\n",
    "    DF = DF.rename(columns=cols_2, errors=\"raise\")\n",
    "    \n",
    "    DF = DF.drop(columns = [35,36,37,38], axis =1)\n",
    "    cols_3={39: \"SensorID\", 40: \"Sensor_4Status\", 41: \"X_UL\", 42: \"Y_UL\", 43:\"Z_UL\"}\n",
    "    DF = DF.rename(columns=cols_3, errors=\"raise\")\n",
    "    \n",
    "    DF = DF.drop(columns = [44,45,46,47], axis =1)\n",
    "    cols_4={48: \"SensorID\", 49: \"Sensor_5Status\", 50: \"X_LL\", 51: \"Y_LL\", 52:\"Z_LL\"}\n",
    "    DF = DF.rename(columns=cols_4, errors=\"raise\")\n",
    "    \n",
    "    DF = DF.drop(columns = [53,54,55,56], axis =1)\n",
    "    cols_5={57: \"SensorID\", 58: \"Sensor_6Status\", 59: \"X_JR\", 60: \"Y_JR\", 61:\"Z_JR\"}\n",
    "    DF = DF.rename(columns=cols_5, errors=\"raise\")\n",
    "    \n",
    "    DF = DF.drop(columns = [62,63,64,65], axis =1)\n",
    "    cols_6={66: \"SensorID\", 67: \"Senson_7Status\", 68: \"X_JL\", 69: \"Y_JL\", 70:\"Z_JL\"}\n",
    "    DF = DF.rename(columns=cols_6, errors=\"raise\")\n",
    "    DF = DF.drop(columns = [71,72,73,74], axis =1)\n",
    "    return DF\n",
    "\n",
    "# cleaning video data \n",
    "\n",
    "def cleaning_video_df(DF):\n",
    "    \n",
    "    # choose the needed columns and convert the values to mm\n",
    "    DF = DF[[\"BAG_Frame_number\",'Time_Stamp (s)','Video_Frame_number',\n",
    "             'landmark_48', 'landmark_48.1', 'landmark_48.2', 'landmark_54',\n",
    "            'landmark_54.1', 'landmark_54.2', 'landmark_51', 'landmark_51.1',\n",
    "            'landmark_51.2', 'landmark_57', 'landmark_57.1', 'landmark_57.2']]\n",
    "  \n",
    "    \n",
    "    DF = DF.rename(columns={'Time_Stamp (s)': 'Time', \"landmark_48\": \"X_LR\", \"landmark_48.1\": \"Y_LR\",\n",
    "                           \"landmark_48.2\": \"Z_LR\", \"landmark_54\": \"X_LLeft\",\n",
    "                           \"landmark_54.1\": \"Y_LLeft\", \"landmark_54.2\": \"Z_LLeft\",\n",
    "                           \"landmark_51\": \"X_UL\", \"landmark_51.1\": \"Y_UL\",\n",
    "                           \"landmark_51.2\": \"Z_UL\", \"landmark_57\": \"X_LL\", \"landmark_57.1\": \"Y_LL\",\n",
    "                           \"landmark_57.2\": \"Z_LL\"})\n",
    "    \n",
    "    DF = DF.astype({ \"X_LR\": np.double, \"Y_LR\": np.double,\"Z_LR\": np.double, \"X_LLeft\": np.double,\n",
    "                            \"Y_LLeft\": np.double, \"Z_LLeft\": np.double, \"X_UL\": np.double,  \"Y_UL\": np.double,\n",
    "                            \"Z_UL\": np.double,  \"X_LL\": np.double,  \"Y_LL\": np.double, \"Z_LL\": np.double})\n",
    "    \n",
    "    # conver the values from m to mm\n",
    "    DF[[\"X_LR\", \"Y_LR\",\"Z_LR\", \"X_LLeft\", \"Y_LLeft\", \"Z_LLeft\", \"X_UL\",  \"Y_UL\",\"Z_UL\",  \"X_LL\", \n",
    "       \"Y_LL\", \"Z_LL\"]] =  DF[[\"X_LR\", \"Y_LR\",\"Z_LR\", \"X_LLeft\", \"Y_LLeft\", \"Z_LLeft\", \"X_UL\",  \"Y_UL\",\"Z_UL\",  \"X_LL\", \n",
    "       \"Y_LL\", \"Z_LL\"]]*1000\n",
    "    return DF\n",
    "\n",
    "def area_of_triangle(A,B,C):\n",
    "\n",
    "    \"\"\"\n",
    "    computes the area of a triangle given by 3 points in 2d or 3d\n",
    "\n",
    "    A, B and C must be numpy arrays\n",
    "\n",
    "    it works with vectors A=[a1,a2,a3], B=[b1,b2,b3], c=[c1,c2,c3] or matrices\n",
    "\n",
    "    A=[[a11,a12,a13],...[a1n,a2n,b3n]], B=[[b11,b12,b13],...[b1n,b2n,b3n]], C=[[c11,c12,c13],...[c1n,c2n,c3n]]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    As = A.shape\n",
    "    Bs = B.shape\n",
    "    Cs = C.shape\n",
    "   \n",
    "    if len(As) == 1 :\n",
    "\n",
    "        #we got vectors\n",
    "\n",
    "        if (As[0]>3) or (Bs[0]>3) or (Cs[0]>3):\n",
    "\n",
    "            raise Exception('coordinates can only be 2d or 3d')\n",
    "\n",
    "            return None\n",
    "\n",
    "    else:\n",
    "\n",
    "        #check at least one of the dimensions is two or three\n",
    "        if (As[0]==2) or (As[0]==3) or (As[1]==2) or (As[1]==3):\n",
    "\n",
    "            #one of the dimensions of A is 2 or 3, now check that all the vectors have the same size\n",
    "            if (As!=Bs) or (As!=Cs):\n",
    "\n",
    "                raise Exception('vectors must be the same size')\n",
    "                return None\n",
    "\n",
    "            else:\n",
    "                #move forward\n",
    "                pass\n",
    "\n",
    "        else:\n",
    "\n",
    "            raise Exception('coordinates can only be 2d or 3d')\n",
    "\n",
    "            return None\n",
    "\n",
    "    #at this point we know that one of the dimensions has 2 or 3 elements we move forward assuming that\n",
    "    #the user provided the vectors with the correct size\n",
    "    #move all vectors to the same origin\n",
    "\n",
    "    AB = B-A\n",
    "    AC = C-A  \n",
    "\n",
    "    if len(As) == 1 :\n",
    "\n",
    "        #if only one vector the simply compute the norm of the cross product\n",
    "        area = (1/2)*np.linalg.norm(np.cross(AB,AC))\n",
    "\n",
    "    else:\n",
    "\n",
    "        #if only multiple vectors compute the norm along the axis one\n",
    "        area = (1/2)*np.linalg.norm(np.cross(AB,AC), axis = 1)   \n",
    "\n",
    "    return area\n",
    "\n",
    "def lipDist(DF):\n",
    "    \n",
    "    # Assumes columns are named in a particular way \n",
    "    \n",
    "    DF['Horiz_Lip_Motion'] = DF.apply(lambda row: math.sqrt((row.X_LLeft - row.X_LR)**2 + (row.Y_LLeft - row.Y_LR)**2\n",
    "                                                                  + (row.Z_LLeft - row.Z_LR)**2), axis = 1) \n",
    "    DF['Vert_Lip_Motion'] = DF.apply(lambda row: math.sqrt((row.X_UL - row.X_LL)**2 + (row.Y_UL - row.Y_LL)**2 +\n",
    "                                                                 (row.Z_UL - row.Z_LL)**2), axis = 1)\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPeakIndex(array, minThreshold = 50, widthapart = 50,  twosided = True):\n",
    "    \n",
    "    peaks, _ = signal.find_peaks(array, height= minThreshold, distance= widthapart)\n",
    "    \n",
    "    if twosided == True:\n",
    "        peaks_neg, _ = signal.find_peaks(-array, height= minThreshold, distance= widthapart)\n",
    "        peaks = np.concatenate((peaks, peaks_neg), axis=None)\n",
    "        peaks = np.sort(peaks, axis=None)\n",
    "    \n",
    "    return peaks\n",
    "        \n",
    "\n",
    "def rom(list_of_arrays):\n",
    "\n",
    "    \n",
    "    reps_max_values = np.array([np.max(array) for array in list_of_arrays])\n",
    "    reps_min_values = np.array([np.min(array) for array in list_of_arrays])\n",
    "    \n",
    "    \n",
    "    ROM = reps_max_values - reps_min_values\n",
    "    \n",
    "    return ROM\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal Processing\n",
    "\n",
    "# sampling frequency set to 100 HZ\n",
    "fsample = 100\n",
    "\n",
    "def sig_shift(signal, amount):\n",
    "    length = len(signal)    \n",
    "    shifted = np.zeros(length+amount - 1)\n",
    "    shifted[:amount-1] = 0\n",
    "    shifted[amount-1:] = signal[:]\n",
    "    return shifted\n",
    "\n",
    "def sig_norm(signal):\n",
    "    signal_mean = np.mean(signal)\n",
    "    signal_normalised = signal - signal_mean\n",
    "    return signal_normalised\n",
    "\n",
    "# Butterworth filter 8-order, 15hz cutoff\n",
    "fc = 15\n",
    "w = fc / (fsample/2)\n",
    "b , a = signal.butter(8, w, btype ='lowpass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading, Cleaning, and Preprocessing DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tasks = ['REST', 'OPEN', 'SPREAD', 'OOEE', 'PA', 'BBP', 'TNG_PROTRUSION', 'TNG_LAT', 'TNG_NOSE']\n",
    "Conditions = ['FAST', 'SLOW', 'DIS', 'HOLD', 'NORM']\n",
    "\n",
    "TASK_DFS_VIDEO_LIST = list()\n",
    "TASK_DFS_WAVE_LIST = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a task to do the analysis on,for example open, spread, pa, bbp, etc\n",
    "Task = Tasks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DJ OPEN_HOLD\n",
      "DJ OPEN_NORM\n",
      "DJ OPEN_DIS\n",
      "DJ OPEN_FAST\n",
      "MK OPEN_HOLD\n",
      "MK OPEN_NORM\n",
      "MK OPEN_DIS\n",
      "MK OPEN_FAST\n",
      "RM OPEN_HOLD\n",
      "RM OPEN_NORM\n",
      "RM OPEN_DIS\n",
      "RM OPEN_FAST\n"
     ]
    }
   ],
   "source": [
    "#####   WAVE DATA   ######\n",
    "\n",
    "# read the wave data files of the chosen task into dfs and store them all in a list \n",
    "path_w = r'C:\\Users\\jafarid\\Documents\\Code\\ValidationStudy\\wave_data'\n",
    "ext_w=('.tsv')\n",
    "Files_w = os.listdir(path_w)           \n",
    "Files_w = [i for i in Files_w if i.endswith(ext_w)]\n",
    "\n",
    "for i in range(0, len(Files_w)):\n",
    "    # choose which task to focus on \n",
    "    if Task in Files_w[i]:\n",
    "        df = pd.read_csv(path_w+ \"\\\\\" + Files_w[i], delimiter='\\t', skiprows=1,header=None)\n",
    "        df = cleaning_wave_df(df)\n",
    "        # depending on the file we are reading the indexing below needs to change \n",
    "        #if Files_w[i][20:-4] == 'EN_HOLD_1' or Files_w[i][20:-4] == 'EN_HOLD':\n",
    "        #    df['FileName'] = Files_w[i][18:-4]\n",
    "        \n",
    "        #else: \n",
    "        df['FileName'] = Files_w[i][18:-4]\n",
    "        df['PatientID'] = Files_w[i][:2]\n",
    "        df['DataDATE'] = Files_w[i][5:13]\n",
    "        df['Task'] = Task\n",
    "        for condition in Conditions:\n",
    "            if condition in Files_w[i]:\n",
    "                df['Condition'] = condition\n",
    "\n",
    "            else:\n",
    "                df['Condition'] = 'NORM'\n",
    "                \n",
    "   \n",
    "        # preprocessing, using the cubic interpolation to fill in the missing data \n",
    "        df = df.interpolate(method ='cubic', limit_direction ='forward') \n",
    "        df = lipDist(df)\n",
    "\n",
    "        #left_area = area_of_triangle(df[[\"X_LLeft\", \"Y_LLeft\", \"Z_LLeft\"]].values, df[[\"X_UL\",  \"Y_UL\",\"Z_UL\"]].values, \n",
    "        #                               df[[\"X_LL\", \"Y_LL\", \"Z_LL\"]].values)\n",
    "        #df['Area_Left'] = np.array(left_area)\n",
    "        #right_area = area_of_triangle(df[[\"X_LR\", \"Y_LR\",\"Z_LR\"]].values, df[[\"X_UL\",  \"Y_UL\",\"Z_UL\"]].values, \n",
    "        #                                df[[ \"X_LL\", \"Y_LL\", \"Z_LL\"]].values)\n",
    "        #df['Area_Right'] =  np.array(right_area)        \n",
    "        #df[\"Area_Ratio\"] = df.apply(lambda row: row.Area_Left/row.Area_Right, axis = 1)\n",
    "        \n",
    "        # Gaussian filter\n",
    "        \n",
    "        df['Horiz_Lip_Motion_F1'] = signal.filtfilt(b, a, df['Horiz_Lip_Motion'])\n",
    "        \n",
    "        df[\"Speed\"] = np.gradient(df['Vert_Lip_Motion'], df[\"Time\"])\n",
    "        \n",
    "        # Butterworth filter 8-order, 15hz cutoff\n",
    "        df['Vert_Lip_Motion_F1']= signal.filtfilt(b, a, df['Vert_Lip_Motion'])\n",
    "        #df['Vert_Lip_Motion_F2']= gaussian_filter(df['Vert_Lip_Motion_F1'], sigma=3)\n",
    "        # speed\n",
    "        #df[\"Speed_F1\"] = signal.filtfilt(b, a, np.gradient(df['Vert_Lip_Motion'], df[\"Time\"]))\n",
    "        \n",
    "        TASK_DFS_WAVE_LIST.append(df)\n",
    "        \n",
    "        print(Files_w[i][:2],Files_w[i][18:-4])\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    %matplotlib qt\n",
    "    plt.plot(TASK_DFS_WAVE_LIST[3]['Vert_Lip_Motion'],'b')\n",
    "    plt.plot(TASK_DFS_WAVE_LIST[3]['Vert_Lip_Motion_F1'],'g')\n",
    "    plt.plot(TASK_DFS_WAVE_LIST[3]['Vert_Lip_Motion_F2'],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN_DIS\n",
      "OPEN_FAST\n",
      "OPEN_HOLD\n",
      "OPEN_NORM\n",
      "OPEN_DIS\n",
      "OPEN_FAST\n",
      "OPEN_HOLD\n",
      "OPEN_NORM\n",
      "OPEN_DIS\n",
      "OPEN_FAST\n",
      "OPEN_HOLD\n",
      "OPEN_NORM\n"
     ]
    }
   ],
   "source": [
    "#####   VIDEO DATA   ######\n",
    "\n",
    "# read the wave data files of the chosen task into dfs and store them all in a list \n",
    "path_v = r'C:\\Users\\jafarid\\Documents\\Code\\ValidationStudy\\video_data_processed'\n",
    "ext_v=('_Landmarks3D.csv')\n",
    "Files_v = os.listdir(path_v)           \n",
    "Files_v = [i for i in Files_v if i.endswith(ext_v)]\n",
    "\n",
    "for i in range(0, len(Files_v)):\n",
    "    # choose which task to focus on \n",
    "    if Task in Files_v[i]:\n",
    "        df = pd.read_csv(path_v+ \"\\\\\" + Files_v[i])\n",
    "        df =  df.drop([0]) \n",
    "        df = cleaning_video_df(df)\n",
    "        # depending on the file we are reading the indexing below needs to change \n",
    "        df['FileName'] = Files_v[i][12:-16]\n",
    "        df['PatientID'] = Files_v[i][:2]\n",
    "        #df['DataDATE'] = Files_v[i][5:13]\n",
    "        df['Task'] = Task\n",
    "        for condition in Conditions:\n",
    "            if condition in Files_v[i]:\n",
    "                df['Condition'] = condition\n",
    "\n",
    "            else:\n",
    "                df['Condition'] = 'NORM'\n",
    "                \n",
    "\n",
    "        # preprocessing, using the cubic interpolation to fill in the missing data \n",
    "        df = df.interpolate(method ='cubic', limit_direction ='forward') \n",
    "        df = lipDist(df)\n",
    "\n",
    "        #left_area = area_of_triangle(df[[\"X_LLeft\", \"Y_LLeft\", \"Z_LLeft\"]].values, df[[\"X_UL\",  \"Y_UL\",\"Z_UL\"]].values, \n",
    "        #                               df[[\"X_LL\", \"Y_LL\", \"Z_LL\"]].values)\n",
    "        #df['Area_Left'] = np.array(left_area)\n",
    "        #right_area = area_of_triangle(df[[\"X_LR\", \"Y_LR\",\"Z_LR\"]].values, df[[\"X_UL\",  \"Y_UL\",\"Z_UL\"]].values, \n",
    "        #                                df[[ \"X_LL\", \"Y_LL\", \"Z_LL\"]].values)\n",
    "        #df['Area_Right'] =  np.array(right_area)        \n",
    "        #df[\"Area_Ratio\"] = df.apply(lambda row: row.Area_Left/row.Area_Right, axis = 1)\n",
    "        # Butterworth filter 8-order, 15hz cutoff\n",
    "        \n",
    "        df['Vert_Lip_Motion_F1']= signal.filtfilt(b, a, df['Vert_Lip_Motion'])  \n",
    "        df['Horiz_Lip_Motion_F1'] = signal.filtfilt(b, a, df['Horiz_Lip_Motion'])\n",
    "        df[\"Speed\"] = np.gradient(df['Vert_Lip_Motion_F1'], df[\"Time\"])\n",
    "        \n",
    "       # df['Vert_Lip_Motion_F3']= gaussian_filter(df['Vert_Lip_Motion_F1'], sigma=3)\n",
    "       # df['Vert_Lip_Motion_F2']= signal.medfilt(df['Vert_Lip_Motion_F1'], 3)\n",
    "        \n",
    "        #df['Horiz_Lip_Motion_F1']= gaussian_filter(df['Horiz_Lip_Motion'], sigma=3)\n",
    "        \n",
    "        TASK_DFS_VIDEO_LIST.append(df)\n",
    "        print(Files_v[i][12:-16])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    %matplotlib qt\n",
    "    plt.plot(TASK_DFS_VIDEO_LIST[2]['Vert_Lip_Motion'],'o')\n",
    "    plt.plot(TASK_DFS_VIDEO_LIST[2]['Vert_Lip_Motion_F1'],'g')\n",
    "    plt.plot(TASK_DFS_VIDEO_LIST[2]['Vert_Lip_Motion_F2'],'r')\n",
    "    plt.plot(TASK_DFS_VIDEO_LIST[2]['Vert_Lip_Motion_F3'],'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TASK_DFS_WAVE_100HZ_LIST = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jafarid\\AppData\\Local\\Continuum\\anaconda3\\envs\\opecvpytorch_env\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# RESAMPLING TO 100Hz for the wave data\n",
    "\n",
    "for DF_WAVE in TASK_DFS_WAVE_LIST:\n",
    "    WAVE_100HZ = pd.DataFrame()\n",
    "    tmax = len(DF_WAVE.Time) - 1\n",
    "    tmax_value = DF_WAVE.Time[tmax]\n",
    "    tmin_value = DF_WAVE.Time[0]\n",
    "    nsample = fsample*(tmax_value - tmin_value)\n",
    "    perfect_time = np.linspace(tmin_value, tmax_value, num= nsample, endpoint=True)\n",
    "    WAVE_100HZ['Time'] = perfect_time\n",
    "    f_motion = interp1d(DF_WAVE.Time, DF_WAVE['Vert_Lip_Motion_F1'], kind = 'linear')\n",
    "    WAVE_100HZ['Vert_Lip_Motion'] = f_motion(perfect_time)\n",
    "    #df['Horiz_Lip_Motion_F1']\n",
    "    f_speed = interp1d(DF_WAVE.Time, DF_WAVE['Speed'], kind = 'linear')\n",
    "    WAVE_100HZ['Speed'] = f_speed(perfect_time)\n",
    "    WAVE_100HZ['FileName'] = DF_WAVE['FileName'][1]\n",
    "    WAVE_100HZ['PatientID'] = DF_WAVE['PatientID'][1]\n",
    "    TASK_DFS_WAVE_100HZ_LIST.append(WAVE_100HZ)\n",
    "    #print(len(DF_WAVE['Vert_Lip_Motion_F1']))\n",
    "    #print(len(WAVE_100HZ['Vert_Lip_Motion']))\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_DFS_VIDEO_100HZ_LIST = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jafarid\\AppData\\Local\\Continuum\\anaconda3\\envs\\opecvpytorch_env\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Upsampling to 100Hz for the video data\n",
    "for DF_VIDEO in TASK_DFS_VIDEO_LIST:\n",
    "    WAVE_100HZ = pd.DataFrame()\n",
    "    tmax = len(DF_VIDEO.Time) - 1\n",
    "    tmax_value = DF_VIDEO.Time[tmax]\n",
    "    tmin_value = DF_VIDEO.Time[1]\n",
    "    nsample = fsample*(tmax_value - tmin_value)\n",
    "    perfect_time = np.linspace(tmin_value, tmax_value, num= nsample, endpoint=True)\n",
    "    WAVE_100HZ['Time'] = perfect_time\n",
    "    f_motion = interp1d(DF_VIDEO.Time, DF_VIDEO['Vert_Lip_Motion_F1'], kind = 'linear')\n",
    "    WAVE_100HZ['Vert_Lip_Motion'] = f_motion(perfect_time)\n",
    "    f_speed = interp1d(DF_VIDEO.Time, DF_VIDEO['Speed'], kind = 'linear')\n",
    "    WAVE_100HZ['Speed'] = f_speed(perfect_time)\n",
    "    WAVE_100HZ['FileName'] = DF_VIDEO['FileName'][1]\n",
    "    WAVE_100HZ['PatientID'] = DF_VIDEO['PatientID'][1]\n",
    "    TASK_DFS_VIDEO_100HZ_LIST.append(WAVE_100HZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    %matplotlib inline\n",
    "    plt.plot(TASK_DFS_VIDEO_100HZ_LIST[9]['Speed'],'r')\n",
    "    plt.plot(TASK_DFS_WAVE_100HZ_LIST[11]['Speed'],'b')\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    a = sig_norm(TASK_DFS_VIDEO_100HZ_LIST[9]['Speed'].values)\n",
    "    b = sig_norm(TASK_DFS_WAVE_100HZ_LIST[11]['Speed'].values)\n",
    "    plt.plot(a,'r')\n",
    "    plt.plot(b,'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_pc = list()\n",
    "on_pc = list()\n",
    "od_pc = list()\n",
    "of_pc = list()\n",
    "oh_rms_list = list()\n",
    "on_rms_list = list()\n",
    "od_rms_list = list()\n",
    "of_rms_list = list()\n",
    "Final_DFS_LIST = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TASK_DFS_WAVE_100HZ_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN_HOLD\n",
      "Wave index:0\n",
      "Video index:2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-184d69cde3c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphase_align\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwave_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvideo_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mupper_bound\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The phase shift is:{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Code\\ValidationStudy\\signal_alignment.py\u001b[0m in \u001b[0;36mphase_align\u001b[1;34m(reference, target, roi, res)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;31m# compute cross covariance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mccovf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdemean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0munbiased\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;31m# determine if shift if positive/negative\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\opecvpytorch_env\\lib\\site-packages\\statsmodels\\tsa\\stattools.py\u001b[0m in \u001b[0;36mccovf\u001b[1;34m(x, y, unbiased, demean)\u001b[0m\n\u001b[0;32m    855\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrelate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'full'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\opecvpytorch_env\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mcorrelate\u001b[1;34m(a, v, mode)\u001b[0m\n\u001b[0;32m    945\u001b[0m     \"\"\"\n\u001b[0;32m    946\u001b[0m     \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mode_from_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrelate2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(TASK_DFS_WAVE_100HZ_LIST)):\n",
    "    for j in range(len(TASK_DFS_VIDEO_100HZ_LIST)):\n",
    "        \n",
    "        if TASK_DFS_WAVE_100HZ_LIST[i]['PatientID'][1]== TASK_DFS_VIDEO_100HZ_LIST[j]['PatientID'][1]:\n",
    "        \n",
    "            if TASK_DFS_WAVE_100HZ_LIST[i]['FileName'][1]== TASK_DFS_VIDEO_100HZ_LIST[j]['FileName'][1]:\n",
    "                result = pd.DataFrame() \n",
    "                print(TASK_DFS_WAVE_100HZ_LIST[i]['FileName'][1])\n",
    "                print('Wave index:{}'.format(i))\n",
    "                print('Video index:{}'.format(j))\n",
    "\n",
    "                video_n = sig_norm(TASK_DFS_VIDEO_100HZ_LIST[j]['Vert_Lip_Motion'].values)\n",
    "                #v_n = sig_norm(TASK_DFS_VIDEO_100HZ_LIST[j]['Vert_Lip_Motion'].values)\n",
    "                wave_n = sig_norm(TASK_DFS_WAVE_100HZ_LIST[i]['Vert_Lip_Motion'].values)\n",
    "           #     video_n = video_n[200:-50]\n",
    "           #     wave_n = wave_n[200:-50]\n",
    "                time = TASK_DFS_WAVE_100HZ_LIST[i]['Time'].values\n",
    "                time_w = TASK_DFS_WAVE_100HZ_LIST[i]['Time'].values\n",
    "                time_v = TASK_DFS_WAVE_100HZ_LIST[i]['Time'].values\n",
    "           #     time = time[200:-50]\n",
    "                \n",
    "                if len(video_n)<=len(wave_n):\n",
    "                    upper_bound = len(video_n) \n",
    "                else: \n",
    "                    upper_bound = len(wave_n) \n",
    "                    \n",
    "                if TASK_DFS_WAVE_100HZ_LIST[i]['FileName'][1]== \"OPEN_NORM\" and TASK_DFS_WAVE_100HZ_LIST[i]['PatientID'][1]== 'RM':\n",
    "                    s = phase_align(wave_n[500:upper_bound], video_n, [5,upper_bound])\n",
    "                    sp = math.ceil(s) + 500\n",
    "                else:    \n",
    "\n",
    "                    s = phase_align(wave_n, video_n, [5,upper_bound])\n",
    "                print('The phase shift is:{}'.format(s))\n",
    "\n",
    "                sp = math.ceil(s)\n",
    "\n",
    "\n",
    "                video_shifted = sig_shift(TASK_DFS_VIDEO_100HZ_LIST[j]['Vert_Lip_Motion'],sp)\n",
    "                video_speed_shifted = sig_shift(TASK_DFS_VIDEO_100HZ_LIST[j]['Speed'],sp)\n",
    "                video_n_s = sig_shift(video_n, sp)\n",
    "                wave_shifted = TASK_DFS_WAVE_100HZ_LIST[i]['Vert_Lip_Motion'].values\n",
    "                wave_speed_shifted = TASK_DFS_WAVE_100HZ_LIST[i]['Speed'].values\n",
    "                \n",
    "                upper_bound_shifted = upper_bound + sp -1\n",
    "                \n",
    "                if len(wave_shifted)< upper_bound_shifted:\n",
    "                    upper_bound_shifted = len(wave_shifted)\n",
    "                \n",
    "                \n",
    "               # print('Video:{}'.format(len(video_shifted)))\n",
    "               # print('WAVE:{}'.format(len(wave_shifted)))\n",
    "               # print('UPPER_BOUND_SHIFTED:{}'.format(upper_bound_shifted))\n",
    "               # print('UPPER_BOUND:{}'.format(upper_bound))\n",
    "                \n",
    "                name = TASK_DFS_WAVE_100HZ_LIST[i]['PatientID'][1] + '_' + TASK_DFS_WAVE_100HZ_LIST[i]['FileName'][1]\n",
    "                \n",
    "                range_l = sp+100\n",
    "                range_u = upper_bound_shifted-10\n",
    "                \n",
    "                result['Time_WAVE'] = time_w[range_l:range_u]\n",
    "                result['Time_VIDEO'] = time_v[range_l:range_u]\n",
    "                #result['Time'] = time[range_l:range_u]\n",
    "                result['VerDisp_WAVE'] = wave_shifted[range_l:range_u]\n",
    "                result['VerDisp_VIDEO'] = video_shifted[range_l:range_u]\n",
    "                \n",
    "              #  result['HorDisp_WAVE']\n",
    "              #  result['HorDisp_VIDEO']\n",
    "                \n",
    "                result['Speed_WAVE'] = wave_speed_shifted[range_l:range_u]\n",
    "                result['Speed_VIDEO'] = video_speed_shifted[range_l:range_u]\n",
    "                \n",
    "                result['FileName'] = TASK_DFS_WAVE_100HZ_LIST[i]['FileName'][1]\n",
    "                result['PatientID'] = TASK_DFS_WAVE_100HZ_LIST[i]['PatientID'][1]\n",
    "                cvs = 'final_paper_data/OPEN_'+ name +'.csv'\n",
    "                result.to_csv(cvs)\n",
    "                Final_DFS_LIST.append(result)\n",
    "                plt.figure()\n",
    "                \n",
    "               # plt.plot(time[sp:upper_bound_shifted], wave_shifted[sp:upper_bound_shifted],'b', label='Ground truth (WAVE)')\n",
    "               # plt.plot(time[sp:upper_bound_shifted],video_shifted[sp:upper_bound_shifted],'r', label='Video + FAN tracking')\n",
    "                plt.plot(time[range_l:range_u], wave_shifted[range_l:range_u],'b', label='Ground truth (WAVE)')\n",
    "                plt.plot(time[range_l:range_u],video_shifted[range_l:range_u],'r', label='Video + FAN tracking')\n",
    "                plt.legend(loc=\"upper left\")\n",
    "                plt.xlabel('Time (s)')\n",
    "                plt.ylabel('Vertical Range of Motion (mm)')\n",
    "                \n",
    "                plt.savefig('{}'.format(name))\n",
    "               # plt.plot(TASK_DFS_WAVE_100HZ_LIST[i]['Vert_Lip_Motion'],'b')\n",
    "               # plt.plot(TASK_DFS_VIDEO_100HZ_LIST[j]['Vert_Lip_Motion'],'r')\n",
    "                #plt.legend()\n",
    "                #plt.figure()\n",
    "                #a = np.gradient(TASK_DFS_WAVE_100HZ_LIST[i]['Time'])\n",
    "                #plt.plot(a, 'b')\n",
    "                #b = np.gradient(TASK_DFS_VIDEO_100HZ_LIST[j]['Time'])\n",
    "                #plt.plot(b, 'r')\n",
    "                \n",
    "\n",
    "\n",
    "                plt.figure()\n",
    "               # plt.plot(wave_n[100:upper_bound],'b')\n",
    "               # plt.plot(video_n_s[100:upper_bound],'r')\n",
    "                plt.plot(time[range_l:range_u],wave_n[range_l:range_u],'b', label='Normalized Ground truth (WAVE)')\n",
    "                plt.plot(time[range_l:range_u],video_n_s[range_l:range_u],'r', label='Normalized Video + FAN tracking')\n",
    "                plt.legend(loc=\"upper left\")\n",
    "                plt.xlabel('Time (s)')\n",
    "                plt.ylabel('Vertical Range of Motion (mm)')\n",
    "                plt.savefig('{}'.format(name+'Normalized'))\n",
    "               # plt.figure()\n",
    "               # plt.plot(wave_n[100:upper_bound],'b')\n",
    "               # plt.plot(video_n_s[100:upper_bound],'r')\n",
    "               # plt.plot(wave_n[sp:upper_bound_shifted],'b')\n",
    "               # plt.plot(video_n_s[sp:upper_bound_shifted],'r')\n",
    "                \n",
    "                \n",
    "              #  plt.plot(TASK_DFS_WAVE_100HZ_LIST[i]['Vert_Lip_Motion'],'b')\n",
    "              #  plt.plot(video_shifted,'r')\n",
    "                #plt.legend()\n",
    "                \n",
    "                plt.figure()\n",
    "                plt.scatter(wave_shifted[range_l:range_u], video_shifted[range_l:range_u]) \n",
    "                \n",
    "                \n",
    "                r, p = stats.pearsonr(video_n_s[range_l:range_u], wave_n[range_l:range_u])\n",
    "                rms = np.sqrt(np.mean((wave_n[range_l:range_u]-video_n_s[range_l:range_u])**2))\n",
    "                #sum((abs(wave_n[range_l:range_u]-video_n_s[range_l:range_u])**2))/len(wave_n[range_l:range_u])\n",
    "               # rms_list.append(rms)\n",
    "                print('The corrolation r and p-value between the signals are: r{}, p{}'.format(r,p))\n",
    "                print()\n",
    "                if TASK_DFS_WAVE_100HZ_LIST[i]['FileName'][1] == \"OPEN_HOLD\":\n",
    "                    oh_pc.append(r)\n",
    "                    oh_rms_list.append(rms)\n",
    "                    \n",
    "                elif TASK_DFS_WAVE_100HZ_LIST[i]['FileName'][1] == \"OPEN_DIS\":\n",
    "                    od_pc.append(r)\n",
    "                    od_rms_list.append(rms)\n",
    "                    \n",
    "                elif TASK_DFS_WAVE_100HZ_LIST[i]['FileName'][1] == \"OPEN_NORM\":\n",
    "                    on_pc.append(r)\n",
    "                    on_rms_list.append(rms)\n",
    "                else: \n",
    "                    of_pc.append(r)\n",
    "                    of_rms_list.append(rms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(oh_pc)\n",
    "print(on_pc)\n",
    "print(od_pc)\n",
    "print(of_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics \n",
    "from statistics import mean \n",
    "from statistics import stdev \n",
    "print(mean(oh_pc))\n",
    "print(mean(on_pc))\n",
    "print(mean(od_pc))\n",
    "print(mean(of_pc))\n",
    "print()\n",
    "print(stdev(oh_pc))\n",
    "print(stdev(on_pc))\n",
    "print(stdev(od_pc))\n",
    "print(stdev(of_pc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean(of_rms_list),stdev(of_rms_list))\n",
    "print(mean(oh_rms_list),stdev(oh_rms_list))\n",
    "print(mean(od_rms_list),stdev(od_rms_list))\n",
    "print(mean(on_rms_list),stdev(on_rms_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Final_DFS_LIST)):\n",
    "    plt.figure()\n",
    "    plt.plot(Final_DFS_LIST[i]['Time'], Final_DFS_LIST[i]['Speed_WAVE'],\n",
    "             'b',label='Ground truth (WAVE)')\n",
    "    plt.plot(Final_DFS_LIST[i]['Time'],Final_DFS_LIST[i]['Speed_VIDEO'],\n",
    "             'r', label='Video + FAN tracking')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Vertical Range of Motion Velocity(mm/s)')\n",
    "    plt.savefig('{}'.format(Final_DFS_LIST[i]['FileName'][1]+'Velocity'))\n",
    "    r, p = stats.pearsonr(Final_DFS_LIST[i]['Speed_WAVE'], \n",
    "                          Final_DFS_LIST[i]['Speed_VIDEO'])\n",
    "    \n",
    "    \n",
    "    ave_s_w = np.mean(abs(Final_DFS_LIST[i]['Speed_WAVE']))\n",
    "    ave_s_v = np.mean(abs(Final_DFS_LIST[i]['Speed_VIDEO']))\n",
    "    \n",
    "    std_s_w = np.std(abs(Final_DFS_LIST[i]['Speed_WAVE']))\n",
    "    std_s_v = np.std(abs(Final_DFS_LIST[i]['Speed_VIDEO']))\n",
    "    \n",
    "    if Final_DFS_LIST[i]['FileName'][1] == \"OPEN_HOLD\":\n",
    "        oh_pc.append(r)\n",
    "      \n",
    "\n",
    "    elif Final_DFS_LIST[i]['FileName'][1] == \"OPEN_DIS\":\n",
    "        od_pc.append(r)\n",
    "      \n",
    "\n",
    "    elif Final_DFS_LIST[i]['FileName'][1] == \"OPEN_NORM\":\n",
    "        on_pc.append(r)\n",
    "       \n",
    "    else: \n",
    "        of_pc.append(r)\n",
    "      \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN MORE THAN ONCE\n",
    "parsed_df_2 = pd.DataFrame(columns=['PatientID','FileName','REP','ROM_VIDEO','ROM_WAVE', 'SpdAvg_WAVE', \n",
    "                                  'SpdAvg_VIDEO','Disp_WAVE', 'Disp_VIDEO','Time_WAVE', 'Time_VIDEO',\n",
    "                                  'Speed_WAVE', 'Speed_VIDEO'])\n",
    "\n",
    "\n",
    "reps = ['R1', 'R2', 'R3', 'R4', 'R5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = ['R1', 'R2', 'R3', 'R4', 'R5', 'R6']\n",
    "#reps = ['R1', 'R2', 'R3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apnd_adj (d, v, t, i):\n",
    "    d[i] = d[i].append(d[i+1])\n",
    "    v[i] = v[i].append(v[i+1])\n",
    "    t[i] = t[i].append(t[i+1])\n",
    "    d.pop(i+1)\n",
    "    v.pop(i+1)\n",
    "    t.pop(i+1)\n",
    "    return d, v, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df at hand \n",
    "DF = Final_DFS_LIST[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(DF['VerDisp_WAVE'])\n",
    "plt.plot(DF['VerDisp_VIDEO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(-DF['VerDisp_WAVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks, _ = signal.find_peaks(-DF['VerDisp_WAVE'], height= -32, distance= 50)\n",
    "print(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the data for wave and video, displacement and velocity signals\n",
    "\n",
    "reps_w = np.array_split(DF['VerDisp_WAVE'], peaks)\n",
    "reps_w_v = np.array_split(DF['Speed_WAVE'], peaks)\n",
    "reps_w_t = np.array_split(DF['Time_WAVE'], peaks)\n",
    "reps_v = np.array_split(DF['VerDisp_VIDEO'], peaks)\n",
    "reps_v_v = np.array_split(DF['Speed_VIDEO'], peaks)\n",
    "reps_v_t = np.array_split(DF['Time_VIDEO'], peaks)\n",
    "if 1:\n",
    "    reps_v.pop(0)\n",
    "    reps_v_v.pop(0)\n",
    "    reps_v_t.pop(0)\n",
    "    reps_v.pop(-1)\n",
    "    reps_v_v.pop(-1)\n",
    "    reps_v_t.pop(-1)\n",
    "\n",
    "    reps_w.pop(0)\n",
    "    reps_w_v.pop(0)\n",
    "    reps_w_t.pop(0)\n",
    "    reps_w.pop(-1)\n",
    "    reps_w_v.pop(-1)\n",
    "    reps_w_t.pop(-1)\n",
    "\n",
    "print(len(reps_w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0: \n",
    "    reps_w.pop(3)\n",
    "    reps_w_v.pop(3)\n",
    "    reps_w_t.pop(3)\n",
    "\n",
    "    reps_v.pop(3)\n",
    "    reps_v_v.pop(3)\n",
    "    reps_v_t.pop(3)\n",
    "    print(len(reps_v), len(reps_w))\n",
    "\n",
    "\n",
    "if 1: \n",
    "    reps_w.pop(-1)\n",
    "    reps_w_v.pop(-1)\n",
    "    reps_w_t.pop(-1)\n",
    " \n",
    "    reps_v.pop(-1)\n",
    "    reps_v_v.pop(-1)\n",
    "    reps_v_t.pop(-1)\n",
    "    print(len(reps_v), len(reps_w))\n",
    "    \n",
    "if 1: \n",
    "    reps_w.pop(0)\n",
    "    reps_w_v.pop(0)\n",
    "    reps_w_t.pop(0)\n",
    " \n",
    "    reps_v.pop(0)\n",
    "    reps_v_v.pop(0)\n",
    "    reps_v_t.pop(0)\n",
    "    print(len(reps_v),len(reps_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in reps_w:\n",
    "    plt.plot(i)\n",
    "\n",
    "plt.figure()\n",
    "for i in reps_w_v:   \n",
    "    plt.plot(i)\n",
    "    \n",
    "if 0:\n",
    "    plt.figure()\n",
    "    for i in reps_v:\n",
    "        plt.plot(i)\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "for i in reps_w:\n",
    "    plt.plot(i)\n",
    "for i in reps_v:\n",
    "    plt.plot(i)\n",
    "print(len(reps_v),len(reps_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CAUTION\n",
    "#reps_w, reps_w_v, reps_w_t = apnd_adj(reps_w, reps_w_v, reps_w_t, 5)\n",
    "#reps_v, reps_v_v, reps_v_t = apnd_adj(reps_v, reps_v_v, reps_v_t, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROM and AVG speed analysis \n",
    "\n",
    "rom_w = rom(reps_w)\n",
    "rom_v = rom(reps_v)\n",
    "ave_s_w = np.array([np.mean(abs(rep_v)) for rep_v in reps_w_v])\n",
    "ave_s_v = np.array([np.mean(abs(rep_v)) for rep_v in reps_v_v])\n",
    "\n",
    "print(rom_w)\n",
    "print(rom_v)\n",
    "print(ave_s_w)\n",
    "print(ave_s_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df = pd.DataFrame()\n",
    "\n",
    "current_df['REP'] = reps\n",
    "current_df['PatientID'] =  DF['PatientID'][1]\n",
    "current_df['FileName'] = DF['FileName'][1]  \n",
    "current_df['ROM_WAVE'] = rom_w\n",
    "current_df['ROM_VIDEO'] = rom_v\n",
    "current_df['SpdAvg_WAVE'] = ave_s_w\n",
    "current_df['SpdAvg_VIDEO'] = ave_s_v\n",
    "current_df['Time_WAVE'] = reps_w_t  \n",
    "current_df['Time_VIDEO'] = reps_v_t\n",
    "current_df['Disp_WAVE'] = reps_w  \n",
    "current_df['Disp_VIDEO'] = reps_v  \n",
    "current_df['Speed_WAVE'] = reps_w_v \n",
    "current_df['Speed_VIDEO'] = reps_v_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_df = current_df\n",
    "for i in range(len(rep_df)):\n",
    "\n",
    "    print(rep_df['FileName'][i] + '_' + rep_df['REP'][i] )\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(rep_df['Time_WAVE'][i].values, rep_df['Disp_WAVE'][i].values, 'b', label='Ground truth (WAVE)')\n",
    "    plt.plot( rep_df['Time_VIDEO'][i].values,rep_df['Disp_VIDEO'][i].values, 'r', label='Video + FAN tracking')\n",
    "    \n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Vertical Range of Motion (mm)')\n",
    "    plt.savefig('{}'.format('Open_REP_' + rep_df['REP'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df_2 = parsed_df_2.append(current_df,ignore_index=True)\n",
    "\n",
    "print(len(parsed_df_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE SURE TO CHANGE THIS!!!!!!!!!\n",
    "\n",
    "cvs = 'OPEN_PARSED_ANALYSIS_2.csv'\n",
    "parsed_df_2.to_csv(cvs)\n",
    "print(len(parsed_df_2))\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(parsed_df_2)):\n",
    "    rep_df = pd.DataFrame()\n",
    "    \n",
    "    rep_df['Disp_VIDEO'] = parsed_df_2['Disp_VIDEO'][i]\n",
    "    rep_df['Speed_VIDEO'] = parsed_df_2['Speed_VIDEO'][i]\n",
    "    \n",
    "    \n",
    "    rep_df['PatientID'] =  parsed_df_2['PatientID'][i]\n",
    "    rep_df['FileName'] = parsed_df_2['FileName'][i]  \n",
    "\n",
    "    rep_df['ROM_VIDEO'] = parsed_df_2['ROM_VIDEO'] [i]\n",
    "\n",
    "    rep_df['SpdAvg_VIDEO'] = parsed_df_2 ['ROM_VIDEO'][i]\n",
    "    rep_df['Time_WAVE'] = parsed_df_2['Time_WAVE']\n",
    "    rep_df['Time_VIDEO'] = parsed_df_2['Time_VIDEO']\n",
    "    name = parsed_df_2['PatientID'][i] + '_' + parsed_df_2['FileName'][i] + '_Video_' +parsed_df_2['REP'][i] \n",
    "\n",
    "    cvs = 'Parsed_Data2/OPEN_'+ name +'.csv'\n",
    "    rep_df.to_csv(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(parsed_df_2)):\n",
    "    rep_df = pd.DataFrame()\n",
    "    \n",
    "    rep_df['Disp_WAVE'] = parsed_df_2['Disp_WAVE'][i]\n",
    "    rep_df['Speed_WAVE'] = parsed_df_2['Speed_WAVE'][i]\n",
    "    \n",
    "    \n",
    "    rep_df['PatientID'] =  parsed_df_2['PatientID'][i]\n",
    "    rep_df['FileName'] = parsed_df_2['FileName'][i]  \n",
    "\n",
    "    rep_df['ROM_WAVE'] = parsed_df_2['ROM_WAVE'] [i]\n",
    "\n",
    "    rep_df['SpdAvg_WAVE'] = parsed_df_2 ['ROM_WAVE'][i]\n",
    "    name = parsed_df_2['PatientID'][i] + '_' + parsed_df_2['FileName'][i] + '_WAVE_' +parsed_df_2['REP'][i] \n",
    "\n",
    "    cvs = 'Parsed_Data2/OPEN_'+ name +'.csv'\n",
    "    rep_df.to_csv(cvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rep_df)):\n",
    "\n",
    "    print(rep_df['FileName'][i] + '_' + rep_df['REP'][i] )\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(rep_df['Time_WAVE'][i].values, rep_df['Disp_WAVE'][i].values, 'b', label='Ground truth (WAVE)')\n",
    "    plt.plot( rep_df['Time_VIDEO'][i].values,rep_df['Disp_VIDEO'][i].values, 'r', label='Video + FAN tracking')\n",
    "    \n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Vertical Range of Motion (mm)')\n",
    "    plt.savefig('{}'.format('Open_REP_' + rep_df['REP'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(parsed_df_2))\n",
    "#parsed_df_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deniz = parsed_df_2.loc[lambda DF: parsed_df_2['PatientID'] == 'DJ']\n",
    "mk = parsed_df_2.loc[lambda DF: parsed_df_2['PatientID'] == 'MK']\n",
    "rm = parsed_df_2.loc[lambda DF: parsed_df_2['PatientID'] == 'RM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#stats.pearsonr(deniz['ROM_WAVE'].values, deniz['ROM_VIDEO'].values)\n",
    "    \n",
    "print(stats.pearsonr(deniz['ROM_WAVE'].values, deniz['ROM_VIDEO'].values))\n",
    "print(stats.spearmanr(deniz['ROM_WAVE'].values, deniz['ROM_VIDEO'].values))\n",
    "print(stats.spearmanr(deniz['SpdAvg_WAVE'].values, deniz['SpdAvg_VIDEO'].values))\n",
    "print()\n",
    "#print(stats.pearsonr(mk['ROM_WAVE'].values, mk['ROM_VIDEO'].values))\n",
    "print(stats.spearmanr(mk['ROM_WAVE'].values, mk['ROM_VIDEO'].values))\n",
    "print(stats.spearmanr(mk['SpdAvg_WAVE'].values, mk['SpdAvg_VIDEO'].values))\n",
    "print()\n",
    "#print(stats.pearsonr(rm['ROM_WAVE'].values, rm['ROM_VIDEO'].values))\n",
    "print(stats.spearmanr(rm['ROM_WAVE'].values, rm['ROM_VIDEO'].values))\n",
    "print(stats.spearmanr(rm['SpdAvg_WAVE'].values, rm['SpdAvg_VIDEO'].values))\n",
    "print()\n",
    "\n",
    "print(stats.spearmanr(parsed_df_2['ROM_WAVE'].values, parsed_df_2['ROM_VIDEO'].values))\n",
    "print(stats.spearmanr(parsed_df_2['SpdAvg_WAVE'].values, parsed_df_2['SpdAvg_VIDEO'].values))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(deniz['ROM_WAVE'].values, deniz['ROM_VIDEO'].values, label='Participant 1')\n",
    "\n",
    "\n",
    "plt.scatter(mk['ROM_WAVE'].values, mk['ROM_VIDEO'].values, label='Participant 2')\n",
    "\n",
    "plt.scatter(rm['ROM_WAVE'].values, rm['ROM_VIDEO'].values, label='Participant 3')\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Vertical Range of Motion, EMA-Ground truth (mm)')\n",
    "plt.ylabel('Vertical Range of Motion, Video + FAN (mm)')\n",
    "plt.savefig('{}'.format('OPEN_REP_CORR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(deniz)):\n",
    "\n",
    "    print(deniz['FileName'][i] + '_' + deniz['REP'][i] )\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(deniz['Time_WAVE'][i].values, deniz['Disp_WAVE'][i].values, 'b', label='Ground truth (WAVE)')\n",
    "    plt.plot( deniz['Time_VIDEO'][i].values,deniz['Disp_VIDEO'][i].values, 'r', label='Video + FAN tracking')\n",
    "    \n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Vertical Range of Motion (mm)')\n",
    "    plt.savefig('{}'.format('Open_REP_' + deniz['REP'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(deniz['SpdAvg_WAVE'].values, deniz['SpdAvg_VIDEO'].values, label='Participant 1')\n",
    "\n",
    "\n",
    "plt.scatter(mk['SpdAvg_WAVE'].values, mk['SpdAvg_VIDEO'].values, label='Participant 2')\n",
    "\n",
    "plt.scatter(rm['SpdAvg_WAVE'].values, rm['SpdAvg_VIDEO'].values, label='Participant 3')\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Average Vertical Speed, EMA-Ground truth (mm/s)')\n",
    "plt.ylabel('Average Vertical Speed, Video + FAN (mm/s)')\n",
    "plt.savefig('{}'.format('OPEN_REP_CORR_V'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deniz.loc[deniz['FileName'] == 'OPEN_NORM', 'color'] = 1\n",
    "deniz.loc[deniz['FileName'] == 'OPEN_HOLD', 'color']=2\n",
    "deniz.loc[deniz['FileName'] == 'OPEN_FAST', 'color']=3\n",
    "deniz.loc[deniz['FileName'] == 'OPEN_DIS', 'color']=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "colours = ListedColormap(['r','b','g','y'])\n",
    "classes = ['OPEN_NORM', 'OPEN_HOLD', 'OPEN_FAST', 'OPEN_DIS']\n",
    "scatter = plt.scatter(deniz['ROM_WAVE'].values, deniz['ROM_VIDEO'].values, c =deniz['color'].values, cmap=colours)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=classes)\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.xlabel('Vertical Range of Motion, Ground truth (WAVE)')\n",
    "plt.ylabel('Vertical Range of Motion, Video + FAN tracking')\n",
    "plt.savefig('{}'.format('OPEN_REP_CORR_DENIZ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk.loc[mk['FileName'] == 'OPEN_NORM', 'color'] = 1\n",
    "mk.loc[mk['FileName'] == 'OPEN_HOLD', 'color']=2\n",
    "mk.loc[mk['FileName'] == 'OPEN_FAST', 'color']=3\n",
    "mk.loc[mk['FileName'] == 'OPEN_DIS', 'color']=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "colours = ListedColormap(['r','b','g','y'])\n",
    "classes = ['OPEN_NORM', 'OPEN_HOLD', 'OPEN_FAST', 'OPEN_DIS']\n",
    "scatter = plt.scatter(mk['ROM_WAVE'].values, mk['ROM_VIDEO'].values, c =mk['color'].values, cmap=colours)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deniz['ROM_WAVE'].values)\n",
    "print(deniz['ROM_VIDEO'].values)\n",
    "print(deniz['FileName'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in Final_DFS_LIST:\n",
    "    print(df['PatientID'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in Final_DFS_LIST:\n",
    "    peaks, _ = signal.find_peaks(array, height= minThreshold, distance= widthapart)\n",
    "    #ROM_V, V_max, V_min = rom(df['Vert_Lip_Motion'].values, peaks)\n",
    "    \n",
    "    \n",
    "    print(df['Condition'][1])\n",
    "    print(ROM_V, V_max, V_min)\n",
    "    \n",
    "    reps_rom_list = \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    video_n = sig_norm(TASK_DFS_VIDEO_100HZ_LIST[11]['Vert_Lip_Motion'])\n",
    "    wave_n = sig_norm(TASK_DFS_WAVE_100HZ_LIST[9]['Vert_Lip_Motion'])\n",
    "\n",
    "    upper_bound = len(video_n) - 10\n",
    "    upper_bound2 = len(wave_n) - 10\n",
    "\n",
    "    s = phase_align(wave_n[600:1100], video_n, [10,upper_bound])\n",
    "    print('The phase shift is:{}'.format(s))\n",
    "\n",
    "    sp = math.ceil(s) + 600\n",
    "\n",
    "\n",
    "    video_shifted = sig_shift(TASK_DFS_VIDEO_100HZ_LIST[11]['Vert_Lip_Motion'],sp)\n",
    "\n",
    "    if len(video_shifted) <= len(wave_n):\n",
    "        signal_bound = upper_bound + sp\n",
    "    else: \n",
    "        signal_bound = len(wave_n) - 10 \n",
    "\n",
    "    print()\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(TASK_DFS_WAVE_100HZ_LIST[9]['Vert_Lip_Motion'],'b')\n",
    "    plt.plot(TASK_DFS_VIDEO_100HZ_LIST[11]['Vert_Lip_Motion'],'r')\n",
    "\n",
    "    if 0: \n",
    "        plt.figure()\n",
    "        a = np.gradient(TASK_DFS_WAVE_100HZ_LIST[6]['Time'])\n",
    "        plt.plot(a, 'b')\n",
    "        b = np.gradient(TASK_DFS_VIDEO_100HZ_LIST[4]['Time'])\n",
    "        plt.plot(b, 'r')\n",
    "        plt.figure()\n",
    "        plt.plot(TASK_DFS_WAVE_100HZ_LIST[6]['Vert_Lip_Motion'],'b')\n",
    "        plt.plot(video_shifted,'r')\n",
    "\n",
    "        plt.figure()\n",
    "        plt.scatter(TASK_DFS_WAVE_100HZ_LIST[6]['Vert_Lip_Motion'][sp:signal_bound], \n",
    "                    video_shifted[sp:signal_bound])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps = ['R1', 'R2', 'R3', 'R4', 'R5']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df = pd.DataFrame(columns=['PatientID','FileName','REP','Disp_WAVE','Disp_VIDEO','ROM_WAVE','ROM_VIDEO','Speed_WAVE', 'Speed_VIDEO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in Final_DFS_LIST:\n",
    "    current_df['REP'] = reps\n",
    "    current_df['PatientID'] =  df['PatientID'][1]\n",
    "    current_df['FileName'] = df['FileName'][1]\n",
    "    parsed_df = parsed_df.append(current_df,ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "realSenseAdd",
   "language": "python",
   "name": "realsenseadd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
